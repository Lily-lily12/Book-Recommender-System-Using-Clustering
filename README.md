# Recommender-System-Using-Clustering
Clustering is a from of unsupervised machine learning. In a given raw dataset, clusters are formed by initializing centriods, refroming of clusters, re assigning of centroids by finding out the centre of mass of the initial clusters.This methods however falls prey to the random initialization trap which means that final outcome may vary based on the initially assigned clusters. To avoid this we use the kmeans++ method to initialize the centroids.The goal of k means++ method to spread out the initial centroid by assigning the first centroid randomly then selecting the rest of the centroids based on the maximum squared distance. The idea is to push the centroids as far as possible from one another.

There are two types of clustering algorithms: K means Clustering and Hierarchial clustering 
1. K means Clustering=In a given raw dataset, clusters are formed by initializing centriods, refroming of clusters, re assigning of centroids by finding out the centre of mass of the initial clusters.This methods however falls prey to the random initialization trap which means that final outcome may vary based on the initially assigned clusters. To avoid this we use the kmeans++ method to initialize the centroids.The goal of k means++ method to spread out the initial centroid by assigning the first centroid randomly then selecting the rest of the centroids based on the maximum squared distance. The idea is to push the centroids as far as possible from one another.In order to find the optimal number of clusters,we use **the elbow method**.To select the number of optimal clusters, we either use domain knowledge or elbow method.In the elbow method,we get a visual graph plotted between WCSS(Within cluster sum of squares) and number of clusters.By running the K means clustering algorithm multiple times with varying number of clusters, we get different values of WCSS. In the graph,we get optimal number of clusters at the elbow,after that value the decrease in WCSS becomes gradual


2. Hierarchial Clustering = In hierarchial clusering,we consider each point to be a cluster.Hence in the beginning we have N clusters, now two closest clusters are formed into one and we get N-1 clusters,we repeat this process till we get one cluster. In this clustering, dendograms are formed at each stage. Finally we arrive at an optimal number of clusters by selecting the longest vertical line which does not intersect with any extended horizontal line.

   The differences between the two is that hierarchial clustering is not suited for large datasets as it takes a lot of time for computing the dendograms

In this project, I will use both the algorithms and draw differences and similarities between them.

